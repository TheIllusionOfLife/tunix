{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d73703a",
   "metadata": {},
   "source": [
    "# Tunix SFT: Continuation Training (Unrestricted Mode)\n",
    "\n",
    "**Strategy**: Continue Supervised Fine-Tuning on a larger dataset (GlaiveAI) starting from the Session 1 checkpoint.\n",
    "\n",
    "**Prerequisites**:\n",
    "1. Run Session 1 notebook (`tunix_sft_train.ipynb`) and save output.\n",
    "2. Upload the Session 1 output as a Kaggle Dataset (e.g., `tunix-session1-checkpoint`).\n",
    "3. Attach that dataset to this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# Update these paths based on your Kaggle Dataset names\n",
    "\n",
    "# Path to checkpoint from Session 1 (Uploaded as Dataset)\n",
    "# Format: /kaggle/input/{dataset-name}/{folder-structure}\n",
    "# Typically: /kaggle/input/tunix-session1-checkpoint/final_sft_model/checkpoint\n",
    "PREV_CHECKPOINT_PATH = \"/kaggle/input/tunix-session1-checkpoint/final_sft_model/checkpoint\"\n",
    "\n",
    "# Path to new training data (GlaiveAI)\n",
    "# We will download it dynamically if not attached, or use attached.\n",
    "# For Unrestricted, we want the FULL GlaiveAI or a large chunk.\n",
    "DATASET_NAME = \"glaiveai/reasoning-v1-20m\" \n",
    "\n",
    "# Training Config\n",
    "SFT_STEPS = 5000  # More steps for extended training\n",
    "LEARNING_RATE = 5e-6 # Lower LR for continuation\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup & Install ---\n",
    "!pip install -q wandb==0.22.0\n",
    "!pip install -q kagglehub\n",
    "!pip install -q ipywidgets\n",
    "!pip install -q tensorflow\n",
    "!pip install -q tensorflow_datasets\n",
    "!pip install -q tensorboardX\n",
    "!pip install -q transformers\n",
    "!pip install -q grain\n",
    "!pip install \"google-tunix[prod]==0.1.5\"\n",
    "!pip install git+https://github.com/google/qwix\n",
    "\n",
    "# Fix Flax Version\n",
    "!pip uninstall -q -y flax\n",
    "!pip install flax==0.12.0\n",
    "!pip install -q datasets==3.2.0 optax==0.2.4 chex==0.1.88\n",
    "\n",
    "# --- Imports ---\n",
    "import functools\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from flax import nnx\n",
    "import grain\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import kagglehub\n",
    "import optax\n",
    "from orbax import checkpoint as ocp\n",
    "import qwix\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Tunix Imports\n",
    "from tunix.generate import sampler as sampler_lib\n",
    "from tunix.generate import tokenizer_adapter as tokenizer_lib\n",
    "from tunix.models.gemma import model as gemma_lib\n",
    "from tunix.models.gemma import params as params_lib\n",
    "from tunix.sft import peft_trainer\n",
    "\n",
    "# Stability\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.95'\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"/tmp/jax_cache\")\n",
    "print(f\"JAX Devices: {jax.devices()}\")\n",
    "\n",
    "# Constants\n",
    "MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "SFT_OUTPUT_DIR = \"/kaggle/working/sft_continuation_checkpoint\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Model Utilities ---\n",
    "MESH = [(8, 1), (\"fsdp\", \"tp\")]\n",
    "\n",
    "def get_gemma_model(ckpt_path):\n",
    "    # Load Base Model Structure\n",
    "    mesh = jax.make_mesh(*MESH)\n",
    "    model_config = gemma_lib.ModelConfig.gemma2_2b()\n",
    "    abs_gemma: nnx.Module = nnx.eval_shape(\n",
    "        lambda: gemma_lib.Transformer(model_config, rngs=nnx.Rngs(params=0))\n",
    "    )\n",
    "    abs_state = nnx.state(abs_gemma)\n",
    "    abs_state = jax.tree.map(\n",
    "        lambda a, s: jax.ShapeDtypeStruct(a.shape, jnp.bfloat16, sharding=s),\n",
    "        abs_state,\n",
    "        nnx.get_named_sharding(abs_state, mesh),\n",
    "    )\n",
    "    checkpointer = ocp.StandardCheckpointer()\n",
    "    restored_params = checkpointer.restore(ckpt_path, target=abs_state)\n",
    "\n",
    "    graph_def, _ = nnx.split(abs_gemma)\n",
    "    gemma = nnx.merge(graph_def, restored_params)\n",
    "    return gemma, mesh, model_config\n",
    "\n",
    "def get_lora_model(base_model, mesh):\n",
    "    # Tunix LoRA Config\n",
    "    RANK = 64\n",
    "    ALPHA = 64.0\n",
    "    lora_provider = qwix.LoraProvider(\n",
    "        module_path=(\n",
    "            \".*q_einsum|.*kv_einsum|.*gate_proj|.*down_proj|.*up_proj|\"\n",
    "            \".*attn_vec_einsum\"\n",
    "        ),\n",
    "        rank=RANK,\n",
    "        alpha=ALPHA,\n",
    "    )\n",
    "\n",
    "    model_input = base_model.get_model_input()\n",
    "    lora_model = qwix.apply_lora_to_model(\n",
    "        base_model, lora_provider, rngs=nnx.Rngs(params=0), **model_input\n",
    "    )\n",
    "\n",
    "    with mesh:\n",
    "        state = nnx.state(lora_model)\n",
    "        pspecs = nnx.get_partition_spec(state)\n",
    "        sharded_state = jax.lax.with_sharding_constraint(state, pspecs)\n",
    "        nnx.update(lora_model, sharded_state)\n",
    "\n",
    "    return lora_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load Checkpoint & Prepare Model ---\n",
    "\n",
    "# 1. Download Base Model (for tokenizer & structure)\n",
    "if \"KAGGLE_USERNAME\" not in os.environ:\n",
    "    kagglehub.login()\n",
    "\n",
    "kaggle_ckpt_path = kagglehub.model_download(f\"google/gemma-2/flax/gemma2-2b-it\")\n",
    "\n",
    "# Prepare intermediate conversion\n",
    "INTERMEDIATE_CKPT_DIR = \"/tmp/content/intermediate_ckpt/\"\n",
    "if not os.path.exists(INTERMEDIATE_CKPT_DIR):\n",
    "    print(\"Converting base model checkpoint...\")\n",
    "    params = params_lib.load_and_format_params(os.path.join(kaggle_ckpt_path, \"gemma2-2b-it\"))\n",
    "    gemma = gemma_lib.Transformer.from_params(params, version=\"2-2b-it\")\n",
    "    checkpointer = ocp.StandardCheckpointer()\n",
    "    _, state = nnx.split(gemma)\n",
    "    checkpointer.save(os.path.join(INTERMEDIATE_CKPT_DIR, \"state\"), state)\n",
    "    checkpointer.wait_until_finished()\n",
    "    del params, gemma, state\n",
    "    gc.collect()\n",
    "\n",
    "# 2. Initialize Models\n",
    "print(\"Initializing Base Model...\")\n",
    "base_model, mesh, model_config = get_gemma_model(os.path.join(INTERMEDIATE_CKPT_DIR, \"state\"))\n",
    "lora_model = get_lora_model(base_model, mesh=mesh)\n",
    "\n",
    "# 3. Load Previous Session State (LoRA weights)\n",
    "print(f\"Restoring Session 1 Checkpoint from: {PREV_CHECKPOINT_PATH}\")\n",
    "\n",
    "try:\n",
    "    # Map structure for LoRA params\n",
    "    abs_lora_params = jax.tree.map(\n",
    "        lambda x: jax.ShapeDtypeStruct(x.shape, x.dtype),\n",
    "        nnx.state(lora_model, nnx.LoRAParam),\n",
    "    )\n",
    "    \n",
    "    # Restore\n",
    "    prev_checkpointer = ocp.StandardCheckpointer()\n",
    "    restored_lora_params = prev_checkpointer.restore(PREV_CHECKPOINT_PATH, target=abs_lora_params)\n",
    "    \n",
    "    # Update model\n",
    "    nnx.update(lora_model, restored_lora_params)\n",
    "    print(\"✅ Successfully restored previous SFT state.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to restore checkpoint: {e}\")\n",
    "    print(\"Double check PREV_CHECKPOINT_PATH. If this is the first run, this is expected to fail.\")\n",
    "    print(\"CRITICAL: Continuing without loaded state means restarting training from scratch!\")\n",
    "    # raise e # Uncomment to enforce strict loading\n",
    "\n",
    "# 4. Tokenizer\n",
    "tokenizer = tokenizer_lib.Tokenizer(\n",
    "    tokenizer_path=os.path.join(kaggle_ckpt_path, \"tokenizer.model\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load Continuation Dataset (GlaiveAI) ---\n",
    "\n",
    "print(\"Loading GlaiveAI dataset (Streaming Mode)...\")\n",
    "try:\n",
    "    # Stream a larger portion for Unrestricted Mode\n",
    "    # We'll take, say, the next 100k-200k samples, or shuffle and take\n",
    "    glaive_ds = datasets.load_dataset(DATASET_NAME, split=\"train\", streaming=True)\n",
    "    \n",
    "    # Config\n",
    "    NUM_SAMPLES = 100000\n",
    "    \n",
    "    training_samples = []\n",
    "    count = 0\n",
    "    \n",
    "    system_prompt = \"You are a deep thinking AI. Think step by step about the problem and provide your reasoning between <reasoning> and </reasoning> tags. Then, provide the final answer between <answer> and </answer> tags.\"\n",
    "    \n",
    "    print(f\"Collecting {NUM_SAMPLES} samples...\")\n",
    "    for sample in tqdm(glaive_ds):\n",
    "        if count >= NUM_SAMPLES:\n",
    "            break\n",
    "            \n",
    "        q = sample.get(\"instruction\") or sample.get(\"question\")\n",
    "        a = sample.get(\"output\") or sample.get(\"answer\")\n",
    "        \n",
    "        if q and a:\n",
    "            # Simple formatting\n",
    "            full_text = f\"<start_of_turn>user\\n{system_prompt}\\n\\n{q}<end_of_turn>\\n<start_of_turn>model\\n{a}\"\n",
    "            training_samples.append({\"text\": full_text})\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"Collected {len(training_samples)} samples.\")\n",
    "    \n",
    "    # Convert to HuggingFace Dataset for easy batching\n",
    "    sft_dataset = datasets.Dataset.from_list(training_samples)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading GlaiveAI: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Continuation Training ---\n",
    "\n",
    "print(\"Starting SFT Continuation...\")\n",
    "\n",
    "# Optimizer (Lower LR)\n",
    "schedule = optax.warmup_cosine_decay_schedule(\n",
    "    init_value=0.0,\n",
    "    peak_value=LEARNING_RATE,\n",
    "    warmup_steps=100,\n",
    "    decay_steps=SFT_STEPS,\n",
    "    end_value=1e-7\n",
    ")\n",
    "optimizer = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),\n",
    "    optax.adamw(learning_rate=schedule, weight_decay=0.01)\n",
    ")\n",
    "\n",
    "# Training Placeholder (Replace with Tunix Trainer)\n",
    "with mesh:\n",
    "    # num_epochs = 1 (since data is large)\n",
    "    # steps = SFT_STEPS\n",
    "    print(f\"Target Steps: {SFT_STEPS}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "    \n",
    "    # trainer = peft_trainer.PeftTrainer(...)\n",
    "    # trainer.train(sft_dataset)\n",
    "    \n",
    "    print(\"[Placeholder: SFT training loop runs here]\")\n",
    "\n",
    "print(\"Continuation Training Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Save Continuation Model ---\n",
    "FINAL_SAVE_DIR = \"/kaggle/working/final_continuation_model\"\n",
    "os.makedirs(FINAL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "checkpointer = ocp.StandardCheckpointer()\n",
    "checkpointer.save(os.path.join(FINAL_SAVE_DIR, \"checkpoint\"), nnx.state(lora_model, nnx.LoRAParam))\n",
    "checkpointer.wait_until_finished()\n",
    "\n",
    "print(f\"✅ Model saved to {FINAL_SAVE_DIR}\")\n",
    "print(\"1. Download output.\")\n",
    "print(\"2. Upload as Kaggle Model.\")\n",
    "print(\"3. Update Unrestricted Model ID.\")\n",
    "\n",
    "unrestricted_kaggle_model = \"yuyamukai/tunix-gemma2-sft-unrestricted\"\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
